# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1662Lo4A4W7Xdck83sWYZJ0vBAO4lijD5
"""

!nvidia-smi

from google.colab import drive

# Attempt to mount Google Drive; if it fails, print an error message and try again
try:
  drive.mount('/content/gdrive')
except ValueError:
  print("Initial mount failed. Trying again...")
  # Sometimes, clearing the runtime and re-running can resolve the issue
  get_ipython().run_line_magic('reset', '-f')
  drive.mount('/content/gdrive')

# Copy the file (using !cp or get_ipython().system() - both are equivalent in Colab)
!cp -r /content/gdrive/MyDrive/customdataset /content/data

!mkdir /content/data2

!cp -r /content/gdrive/MyDrive/lincece_plate /content/data2

import os
import shutil
from sklearn.model_selection import train_test_split

# Paths
image_dir = "/content/data/images"  # Changed image_dir2 to image_dir
annotation_dir = "/content/data/labell"

# Output folders
output_base = "/content/split_data"
train_img_dir = os.path.join(output_base, "train", "images")
train_ann_dir = os.path.join(output_base, "train", "annotations")
val_img_dir = os.path.join(output_base, "val", "images")
val_ann_dir = os.path.join(output_base, "val", "annotations")

# Create folders
for folder in [train_img_dir, train_ann_dir, val_img_dir, val_ann_dir]:
    os.makedirs(folder, exist_ok=True)

# Get all annotation files
xml_files = [f for f in os.listdir(annotation_dir) if f.endswith(".xml")]

# Split 90% train, 10% val
train_files, val_files = train_test_split(xml_files, train_size=0.9, random_state=42)

def move_files(file_list, target_img_dir, target_ann_dir):
    for xml_file in file_list:
        # Copy XML file
        src_xml = os.path.join(annotation_dir, xml_file)
        shutil.copy(src_xml, target_ann_dir)

        # Copy corresponding image
        img_name = xml_file.replace(".xml", ".png")  # use .jpg if needed
        src_img = os.path.join(image_dir, img_name) # image_dir is now defined
        if os.path.exists(src_img):
            shutil.copy(src_img, target_img_dir)
        else:
            print(f"‚ö†Ô∏è Image file not found for: {xml_file}")

# Move files
move_files(train_files, train_img_dir, train_ann_dir)
move_files(val_files, val_img_dir, val_ann_dir)

print("‚úÖ Dataset split into training and validation sets successfully!")

import os

base_path = "/content/split_data"

for root, dirs, files in os.walk(base_path):
    level = root.replace(base_path, '').count(os.sep)
    indent = ' ' * 2 * level
    print(f"{indent}{os.path.basename(root)}/")
    sub_indent = ' ' * 2 * (level + 1)
    for f in files[:5]:  # show first 5 files
        print(f"{sub_indent}{f}")

!pip install ultralytics

# Create a one-class file called 'licence'
with open("/content/split_data/classes.txt", "w") as f:
    f.write("licence\n")

print("‚úÖ Created classes.txt with one class: licence")

with open("/content/data2/lincece_plate/classes.txt", "w") as f:
    f.write("License_Plate\n")

print("‚úÖ Created classes.txt with one class: License_Plate")

import yaml
import os

def create_data_yaml(path_to_classes_txt, path_to_data_yaml):
    # Read class.txt to get class names
    if not os.path.exists(path_to_classes_txt):
        print(f'‚ùå classes.txt file not found at {path_to_classes_txt}')
        return
    with open(path_to_classes_txt, 'r') as f:
        classes = [line.strip() for line in f.readlines() if line.strip()]
    number_of_classes = len(classes)

    # Create data dictionary with correct paths
    data = {
        'path': '/content/split_data',
        'train': 'train/images',
        'val': 'validation/images',
        'nc': number_of_classes,
        'names': classes
    }

    # Write YAML
    with open(path_to_data_yaml, 'w') as f:
        yaml.dump(data, f, sort_keys=False)
    print(f'‚úÖ Created config file at {path_to_data_yaml}')

# Update paths
path_to_classes_txt = '/content/split_data/classes.txt'
path_to_data_yaml = '/content/data.yaml'

# Run function
create_data_yaml(path_to_classes_txt, path_to_data_yaml)

# Show the contents of the generated data.yaml
print('\nüìÑ File contents of data.yaml:\n')
!cat /content/data.yaml

import os
import xml.etree.ElementTree as ET

# Folder settings
base_dir = "/content/split_data"
sets = ["train", "val"]
class_name = "licence"

def convert_bbox(size, box):
    """Convert VOC bbox to YOLO format."""
    dw = 1.0 / size[0]
    dh = 1.0 / size[1]
    x_center = (box[0] + box[2]) / 2.0
    y_center = (box[1] + box[3]) / 2.0
    w = box[2] - box[0]
    h = box[3] - box[1]
    return (x_center * dw, y_center * dh, w * dw, h * dh)

converted_count = 0

for subset in sets:
    ann_dir = os.path.join(base_dir, subset, "annotations")
    label_dir = os.path.join(base_dir, subset, "labels")
    os.makedirs(label_dir, exist_ok=True)

    for file in os.listdir(ann_dir):
        if not file.endswith(".xml"):
            continue

        xml_path = os.path.join(ann_dir, file)
        try:
            tree = ET.parse(xml_path)
            root = tree.getroot()

            size = root.find("size")
            width = int(size.find("width").text)
            height = int(size.find("height").text)

            txt_path = os.path.join(label_dir, file.replace(".xml", ".txt"))
            with open(txt_path, "w") as f:
                for obj in root.findall("object"):
                    if obj.find("name").text != class_name:
                        continue
                    bbox = obj.find("bndbox")
                    b = (
                        int(bbox.find("xmin").text),
                        int(bbox.find("ymin").text),
                        int(bbox.find("xmax").text),
                        int(bbox.find("ymax").text),
                    )
                    yolo = convert_bbox((width, height), b)
                    f.write(f"0 {' '.join([f'{v:.6f}' for v in yolo])}\n")
                    converted_count += 1
        except Exception as e:
            print(f"‚ùå Error parsing {xml_path}: {e}")

print(f"‚úÖ Done! {converted_count} bounding boxes converted to YOLO format.")

import yaml

def create_data_yaml(path_to_classes_txt, path_to_data_yaml, dataset_base):
    with open(path_to_classes_txt, 'r') as f:
        classes = [line.strip() for line in f.readlines() if line.strip()]
    data = {
        'path': dataset_base,
        'train': 'train/images',
        'val': 'validation/images',
        'nc': len(classes),
        'names': classes
    }
    with open(path_to_data_yaml, 'w') as f:
        yaml.dump(data, f, sort_keys=False)
    print(f"‚úÖ Created data.yaml at {path_to_data_yaml}")

# Paths
create_data_yaml(
    path_to_classes_txt='/content/split_data/classes.txt',
    path_to_data_yaml='/content/data.yaml',
    dataset_base='/content/split_data'
)
# Show the contents of the generated data.yaml
print('\nüìÑ File contents of data.yaml:\n')
!cat /content/data.yaml

data_yaml = """
path: /content/split_data
train: train/images
val: val/images
nc: 1
names: ['licence']
"""

with open("/content/data.yaml", "w") as f:
    f.write(data_yaml)

!yolo task=detect mode=train data=/content/data.yaml model=yfrom ultralytics import YOLO

from ultralytics import YOLO

# Load YOLOv8m for better accuracy
model = YOLO("yolov8m.pt")  # Use 'yolov8l.pt' for even better results

# Train the model with improved settings
model.train(
    data="/content/data.yaml",  # Path to your dataset config
    imgsz=1024,  # Higher resolution for better small object detection
    epochs=150,  # More training time
    batch=16,  # Adjust based on GPU memory
    optimizer="SGD",  # Try SGD instead of AdamW for better generalization
    lr0=0.001,  # Learning rate (try different values)
    lrf=0.01,  # Final learning rate
    mosaic=1.0,  # Stronger data augmentation
    mixup=0.3,  # Helps prevent overfitting
    flipud=0.5,  # Vertical flip augmentation
    fliplr=0.5,  # Horizontal flip augmentation
    hsv_h=0.02, hsv_s=0.8, hsv_v=0.5,  # More color variation
    weight_decay=0.0005,  # Regularization
    workers=8,  # Increase workers for faster training
    patience=50,  # Stop training if no improvement after 50 epochs
    cache=True  # Cache dataset in memory for faster training
)

from IPython.display import Image
Image(filename='runs/detect/train/results.png')

import torch
torch.cuda.empty_cache()

!yolo detect train model=runs/detect/train/weights/best.pt data=/content/data2/lincece_plate/data.yaml epochs=50 imgsz=640

import glob
import os
import cv2
import torch
import matplotlib.pyplot as plt
from ultralytics import YOLO

# Load the trained model
model = YOLO("runs/detect/train/weights/best.pt")  # Update with your model path

# Define the folder containing test images
image_folder = "/content/data2/lincece_plate/test/images"  # Update with actual path

# Get all image files inside the folder
image_files = glob.glob(os.path.join(image_folder, "*.jpg"))
image_files += glob.glob(os.path.join(image_folder, "*.png"))

# Check if images are found
if not image_files:
    print("No images found in the directory!")
else:
    # Run inference on all images
    results = model.predict(image_files, conf=0.25)

    # Display results
    for img_path, result in zip(image_files, results):
        # Convert image to array with detections
        img_with_boxes = result.plot()  # This draws the bounding boxes and labels

        # Convert from BGR to RGB for correct display
        img_with_boxes = cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB)

        # Show the image with detections
        plt.figure(figsize=(8, 6))
        plt.imshow(img_with_boxes)
        plt.axis("off")
        plt.title(f"Detection: {os.path.basename(img_path)}")
        plt.show()

!pip install -U yt-dlp

!yt-dlp  best -o "/content/test_video.%(ext)s" "https://youtu.be/FsGPxhidwGg"

!yolo detect predict model=/content/runs/detect/train2/weights/best.pt source=/content/test_video.mkv save=True

from IPython.display import Video
Video("/content/runs/detect/predict2/test_video.avi", embed=True)

!pip install paddleocr
!pip install paddlepaddle

import cv2
import torch
import os
from paddleocr import PaddleOCR
from ultralytics import YOLO

# Load YOLO model
yolo_model = YOLO("/content/runs/detect/train2/weights/best.pt")  # Ensure correct path

# Load PaddleOCR
ocr = PaddleOCR(use_angle_cls=True, lang='en')  # English OCR

!apt-get update && apt-get install -y ffmpeg

!ffmpeg -i /content/test_video.mkv -c:v libx264 -c:a aac /content/test_video.mp4

# Read video
video_path = "/content/test_video.mp4"  # Update path if needed
cap = cv2.VideoCapture(video_path)

# Video writer setup
output_path = "/content/ocr_result.mp4"
fps = int(cap.get(cv2.CAP_PROP_FPS))
width, height = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break  # Stop if video ends

    # Run YOLOv8 detection
    results = yolo_model(frame)

    for result in results:
        for box in result.boxes.xyxy:
            x1, y1, x2, y2 = map(int, box)  # Bounding box
            plate_crop = frame[y1:y2, x1:x2]  # Crop detected plate

            # Run OCR
            ocr_results = ocr.ocr(plate_crop, cls=True)

            # Extract text
            plate_text = ""
            if ocr_results and ocr_results[0]:
                plate_text = " ".join([word[1][0] for word in ocr_results[0]])

            # Draw bounding box & text on the frame
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(frame, plate_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

    out.write(frame)  # Save frame

cap.release()
out.release()
cv2.destroyAllWindows()

print("OCR processing completed! ‚úÖ")

from IPython.display import Video
Video(output_path, embed=True)

!sudo apt update && sudo apt install ccache -y

!yolo detect predict model=runs/detect/train2/weights/best.pt source='/content/car-ind-number-plate.jpeg'

!ffmpeg -i /content/test_video.mp4

# Load YOLO model
yolo_model = YOLO("/content/runs/detect/train/weights/best.pt")  # Ensure correct path

# Load PaddleOCR
ocr = PaddleOCR(use_angle_cls=True, lang='en')  # English OCR

# Folder containing images
input_folder = "/content/gdrive/MyDrive/archive (4)/Indian_Number_Plates/Sample_Images"  # Change to your folder path
output_folder = "/content/ocr_results/"
os.makedirs(output_folder, exist_ok=True)

# Loop through all images in the folder
for image_name in os.listdir(input_folder):
    if image_name.endswith((".jpg", ".jpeg", ".png")):
        image_path = os.path.join(input_folder, image_name)
        frame = cv2.imread(image_path)

        # Run YOLOv8 detection
        results = yolo_model(frame)

        for result in results:
            for box in result.boxes.xyxy:
                x1, y1, x2, y2 = map(int, box)  # Bounding box
                plate_crop = frame[y1:y2, x1:x2]  # Crop detected plate

                # Run OCR
                ocr_results = ocr.ocr(plate_crop, cls=True)

                # Extract text
                plate_text = ""
                if ocr_results and ocr_results[0]:
                    plate_text = " ".join([word[1][0] for word in ocr_results[0]])

                # Draw bounding box & text on the frame
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(frame, plate_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

                # Save cropped plate
                plate_crop_path = os.path.join(output_folder, f"plate_{image_name}")
                cv2.imwrite(plate_crop_path, plate_crop)

        # Save annotated image
        output_path = os.path.join(output_folder, f"annotated_{image_name}")
        cv2.imwrite(output_path, frame)
        print(f"Processed {image_name}: {plate_text}")

print("‚úÖ OCR processing completed for all images!")

from IPython.display import display
from PIL import Image
import os

image_path = "/content/ocr_results"  # Your output folder
# Get a list of image files in the directory
image_files = [f for f in os.listdir(image_path) if os.path.isfile(os.path.join(image_path, f)) and f.endswith((".jpg", ".jpeg", ".png"))]

# Check if there are any image files
if image_files:
    # Open and display the first image found
    image_to_display = os.path.join(image_path, image_files[0])
    display(Image.open(image_to_display))
else:
    print("No image files found in the directory.")

from ultralytics import YOLO

model = YOLO("/content/runs/detect/train2/weights/best.pt")  # Use your trained model path if retraining
model.train(
    data="/content/data2/lincece_plate/data.yaml",
    epochs=100,
    batch=16,  # Increase batch size if GPU allows
    imgsz=640,  # Increase image size for better resolution
    augment=True,  # Enable augmentation
    hsv_h=0.015,  # Adjust hue augmentation
    hsv_s=0.7,  # Increase saturation augmentation
    hsv_v=0.4,  # Increase brightness augmentation
    flipud=0.5,  # Add vertical flip
    fliplr=0.5,  # Add horizontal flip
    mosaic=1.0,  # Use mosaic augmentation (good for small datasets)
    mixup=0.2,  # Use mixup for varied images
    degrees=5.0,  # Small rotation
    resume=False
)

from IPython.display import Image
Image(filename='runs/detect/train2/results.png')